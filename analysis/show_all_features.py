#!/usr/bin/env python3
"""
Show comprehensive view of all features from the activation sample analysis.
"""

import json
import os
from collections import defaultdict, Counter

def load_analysis_results():
    """Load the analysis results from the JSON file."""
    
    analysis_file = "analysis_results/gemma-2-2b_blocks.8.hook_resid_pre_4608_matryoshka-transcoder_8_0.0003_activation_samples/analysis_results.json"
    
    if not os.path.exists(analysis_file):
        print(f"‚ùå Analysis file not found: {analysis_file}")
        return None
    
    with open(analysis_file, 'r') as f:
        return json.load(f)

def categorize_features_by_activation(analysis_results):
    """Categorize features by activation strength ranges."""
    
    categories = {
        "Very High (30+)": [],
        "High (20-30)": [],
        "Medium (10-20)": [],
        "Low (5-10)": [],
        "Very Low (<5)": []
    }
    
    for feature in analysis_results['top_features']:
        max_activation = feature['max_activation']
        if max_activation >= 30:
            categories["Very High (30+)"].append(feature)
        elif max_activation >= 20:
            categories["High (20-30)"].append(feature)
        elif max_activation >= 10:
            categories["Medium (10-20)"].append(feature)
        elif max_activation >= 5:
            categories["Low (5-10)"].append(feature)
        else:
            categories["Very Low (<5)"].append(feature)
    
    return categories

def analyze_text_patterns(analysis_results):
    """Analyze text patterns across all features."""
    
    all_contexts = []
    feature_categories = defaultdict(list)
    
    for feature in analysis_results['top_features']:
        for example in feature['top_examples']:
            context = example['context'].lower()
            all_contexts.append(context)
            
            # Categorize by content type
            if any(word in context for word in ['function', 'def', 'class', 'import', 'return', 'if', 'for', 'while']):
                feature_categories['Programming'].append(feature['feature_idx'])
            elif any(word in context for word in ['the', 'and', 'of', 'to', 'in', 'is', 'are', 'was', 'were']):
                feature_categories['General Language'].append(feature['feature_idx'])
            elif any(word in context for word in ['<bos>', 'conference', 'leadership', 'african', 'americans']):
                feature_categories['Document Structure'].append(feature['feature_idx'])
            elif any(word in context for word in ['company', 'incorporated', 'borough', 'growth', 'zinc']):
                feature_categories['Business/History'].append(feature['feature_idx'])
            else:
                feature_categories['Other'].append(feature['feature_idx'])
    
    return all_contexts, feature_categories

def show_comprehensive_features(analysis_results):
    """Show a comprehensive view of all features."""
    
    print("=" * 80)
    print("üî¨ COMPREHENSIVE FEATURE ANALYSIS")
    print("=" * 80)
    
    # Basic statistics
    print(f"üìä Overall Statistics:")
    print(f"   Total features analyzed: {len(analysis_results['top_features'])}")
    print(f"   Total samples collected: {analysis_results['sample_summary']['total_samples_collected']:,}")
    print(f"   Average samples per feature: {analysis_results['sample_summary']['average_samples_per_feature']:.1f}")
    
    # Categorize features by activation strength
    categories = categorize_features_by_activation(analysis_results)
    
    print(f"\nüìà Feature Categories by Activation Strength:")
    for category, features in categories.items():
        print(f"   {category}: {len(features)} features")
    
    # Show features from each category
    print(f"\nüéØ Features by Activation Category:")
    
    for category, features in categories.items():
        if not features:
            continue
            
        print(f"\n   {category} ({len(features)} features):")
        
        # Show top 3 features from each category
        for i, feature in enumerate(features[:3], 1):
            print(f"      #{i} Feature {feature['feature_idx']}:")
            print(f"         Max activation: {feature['max_activation']:.2f}")
            print(f"         Mean activation: {feature['mean_activation']:.2f}")
            print(f"         Sample count: {feature['sample_count']}")
            
            # Show top example
            if feature['top_examples']:
                top_example = feature['top_examples'][0]
                print(f"         Top example: '{top_example['context'][:60]}{'...' if len(top_example['context']) > 60 else ''}'")
                print(f"         Activation: {top_example['activation']:.2f}, Position: {top_example['position']}")
    
    # Analyze text patterns
    all_contexts, feature_categories = analyze_text_patterns(analysis_results)
    
    print(f"\nüìù Text Pattern Analysis:")
    print(f"   Total contexts analyzed: {len(all_contexts)}")
    print(f"   Average context length: {sum(len(c.split()) for c in all_contexts) / len(all_contexts):.1f} words")
    
    print(f"\n   Feature Categories by Content Type:")
    for category, features in feature_categories.items():
        unique_features = len(set(features))
        print(f"      {category}: {unique_features} features")
    
    # Show word frequency
    all_words = []
    for context in all_contexts:
        all_words.extend(context.split())
    
    word_freq = Counter(all_words)
    common_words = word_freq.most_common(15)
    
    print(f"\n   Most Common Words Across All Features:")
    for word, count in common_words:
        print(f"      '{word}': {count} occurrences")

def show_specific_feature_ranges(analysis_results):
    """Show features from specific ranges to give more variety."""
    
    print(f"\n" + "=" * 80)
    print("üîç DETAILED FEATURE EXAMPLES FROM DIFFERENT RANGES")
    print("=" * 80)
    
    # Show features from different ranking ranges
    ranges = [
        ("Top 1-10", 0, 10),
        ("Top 11-20", 10, 20),
        ("Top 21-30", 20, 30),
        ("Top 31-50", 30, 50),
        ("Top 51-100", 50, 100),
    ]
    
    for range_name, start, end in ranges:
        if start >= len(analysis_results['top_features']):
            break
            
        features_in_range = analysis_results['top_features'][start:end]
        
        print(f"\nüéØ {range_name} Features:")
        
        for i, feature in enumerate(features_in_range, start + 1):
            print(f"\n   #{i} Feature {feature['feature_idx']}:")
            print(f"      Max activation: {feature['max_activation']:.2f}")
            print(f"      Mean activation: {feature['mean_activation']:.2f}")
            print(f"      Sample count: {feature['sample_count']}")
            
            # Show all examples for this feature
            print(f"      Examples:")
            for j, example in enumerate(feature['top_examples'], 1):
                print(f"         {j}. Activation: {example['activation']:.2f}")
                print(f"            Context: '{example['context']}'")
                print(f"            Position: {example['position']}")

def show_interpretability_insights(analysis_results):
    """Show interpretability insights from the analysis."""
    
    print(f"\n" + "=" * 80)
    print("üß† INTERPRETABILITY INSIGHTS")
    print("=" * 80)
    
    print(f"üîç Key Observations:")
    print(f"   1. **High Activation Features**: Features with activations >30 show strong specialization")
    print(f"   2. **Document Structure**: Many top features activate for document beginnings (<bos> tokens)")
    print(f"   3. **Content Specialization**: Features learn to recognize specific content patterns")
    print(f"   4. **Position Sensitivity**: Features often activate at specific positions in sequences")
    
    # Analyze position patterns
    position_counts = defaultdict(int)
    for feature in analysis_results['top_features'][:50]:  # Top 50 features
        for example in feature['top_examples']:
            position_counts[example['position']] += 1
    
    print(f"\n   üìç Position Analysis (Top 50 features):")
    for position in sorted(position_counts.keys()):
        count = position_counts[position]
        print(f"      Position {position}: {count} activations")
    
    # Analyze context patterns
    print(f"\n   üìù Context Pattern Analysis:")
    
    # Count features that activate for specific patterns
    bos_features = 0
    programming_features = 0
    business_features = 0
    
    for feature in analysis_results['top_features'][:100]:  # Top 100 features
        contexts = [ex['context'].lower() for ex in feature['top_examples']]
        if any('<bos>' in ctx for ctx in contexts):
            bos_features += 1
        if any(word in ' '.join(contexts) for word in ['function', 'def', 'class', 'import']):
            programming_features += 1
        if any(word in ' '.join(contexts) for word in ['company', 'incorporated', 'business', 'corporate']):
            business_features += 1
    
    print(f"      Features activating for document beginnings: {bos_features}")
    print(f"      Features with programming-related contexts: {programming_features}")
    print(f"      Features with business-related contexts: {business_features}")

def main():
    """Main function to show comprehensive feature analysis."""
    
    print("üî¨ Loading and analyzing all features from the training results...")
    
    # Load analysis results
    analysis_results = load_analysis_results()
    if analysis_results is None:
        return
    
    # Show comprehensive analysis
    show_comprehensive_features(analysis_results)
    
    # Show specific feature ranges
    show_specific_feature_ranges(analysis_results)
    
    # Show interpretability insights
    show_interpretability_insights(analysis_results)
    
    print(f"\n" + "=" * 80)
    print("üéâ COMPREHENSIVE FEATURE ANALYSIS COMPLETE!")
    print("=" * 80)
    print(f"‚úÖ Analyzed {len(analysis_results['top_features'])} features")
    print(f"‚úÖ Found {analysis_results['sample_summary']['total_samples_collected']:,} total activation samples")
    print(f"‚úÖ Features show clear specialization patterns")
    print(f"‚úÖ All samples contain real training data contexts")
    print(f"‚úÖ Features successfully store activation samples from training data!")
    print("=" * 80)

if __name__ == "__main__":
    main()
