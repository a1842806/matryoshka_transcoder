{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\ude80 Matryoshka Transcoder Training (Nested Groups) - Private Repo\n",
        "\n",
        "This notebook trains a Matryoshka Transcoder with **nested groups** architecture on Google Colab using your private repository.\n",
        "\n",
        "## \ud83d\udd10 Private Repository Access\n",
        "This notebook uses a **Personal Access Token** for secure authentication with your private GitHub repository.\n",
        "\n",
        "## \ud83c\udfaf What You'll Get\n",
        "- **Nested Groups**: Each group includes all previous groups (matches original paper)\n",
        "- **Hierarchical Learning**: Features organize from coarse to fine\n",
        "- **Adaptive Complexity**: Each group is a complete model\n",
        "- **Interpretability**: Activation samples for feature analysis\n",
        "\n",
        "## \ud83d\udcca Training Options\n",
        "- **Layer 17** (Recommended): ~6 hours, research quality\n",
        "- **Layer 8** (Quick Test): ~30 minutes, proof of concept\n",
        "- **Layer 12** (Alternative): ~8 hours, mid-layer analysis\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd27 Setup & Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "print(\"\ud83d\udda5\ufe0f  GPU Check:\")\n",
        "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"   \u26a0\ufe0f  No GPU detected! Go to Runtime \u2192 Change runtime type \u2192 T4 GPU\")\n",
        "\n",
        "print(\"\\n\ud83d\udce6 Installing dependencies...\")\n",
        "%pip install torch transformers transformer-lens wandb datasets einops jaxtyping -q\n",
        "print(\"\u2705 Dependencies installed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository with nested groups implementation\n",
        "print(\"\ud83d\udce5 Cloning repository...\")\n",
        "print(\"   This will use your personal access token for authentication\")\n",
        "\n",
        "# Get token from user\n",
        "import getpass\n",
        "token = getpass.getpass(\"Enter your GitHub Personal Access Token: \")\n",
        "\n",
        "# Clone using token authentication\n",
        "!git clone https://{token}@github.com/a1842806/matryoshka_transcoder.git\n",
        "%cd matryoshka_transcoder\n",
        "\n",
        "# Switch to the nested groups branch\n",
        "!git checkout interpretability-evaluation\n",
        "!git pull\n",
        "print(\"\u2705 Repository cloned and updated\")\n",
        "\n",
        "# Verify we're on the right branch\n",
        "!git branch --show-current\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd10 Weights & Biases Setup (Optional)\n",
        "\n",
        "W&B tracks your training metrics. You can skip this if you don't want to use it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Login to Weights & Biases (optional)\n",
        "import wandb\n",
        "print(\"\ud83d\udd10 Weights & Biases Login\")\n",
        "print(\"   This will open a browser tab for authentication\")\n",
        "print(\"   You can skip this by interrupting the cell (Ctrl+C)\")\n",
        "\n",
        "try:\n",
        "    wandb.login()\n",
        "    print(\"\u2705 W&B login successful\")\n",
        "except:\n",
        "    print(\"\u26a0\ufe0f  W&B login skipped - metrics won't be tracked online\")\n",
        "    print(\"   Training will still work, just without W&B dashboard\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf Choose Training Configuration\n",
        "\n",
        "Select one of the training options below:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 1: Layer 17 (Recommended) - ~6 hours on T4 GPU\n",
        "\n",
        "**Best for**: Research quality results, final training\n",
        "- Dictionary size: 18,432 features (nested groups)\n",
        "- Training steps: ~15,000\n",
        "- Features: Activation sample collection\n",
        "- Optimized hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train on Layer 17 (RECOMMENDED)\n",
        "print(\"\ud83d\ude80 Starting Layer 17 training...\")\n",
        "print(\"   This will take ~6 hours on T4 GPU\")\n",
        "print(\"   You can monitor progress on W&B dashboard\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "!python src/scripts/train_gemma_layer17_with_warmup_decay_samples.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 2: Layer 8 (Quick Test) - ~30 minutes on T4 GPU\n",
        "\n",
        "**Best for**: Testing setup, quick experiments\n",
        "- Dictionary size: 18,432 features (nested groups)\n",
        "- Training steps: ~1,000\n",
        "- Fast iteration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train on Layer 8 (QUICK TEST)\n",
        "print(\"\ud83d\ude80 Starting Layer 8 training...\")\n",
        "print(\"   This will take ~30 minutes on T4 GPU\")\n",
        "print(\"   Good for testing your setup\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "!python src/scripts/train_gemma_layer8_with_warmup_decay_samples.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 3: Layer 12 (Alternative) - ~8 hours on T4 GPU\n",
        "\n",
        "**Best for**: Mid-layer analysis, comprehensive training\n",
        "- Dictionary size: 36,864 features (nested groups)\n",
        "- Training steps: ~20,000\n",
        "- Full training run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train on Layer 12 (ALTERNATIVE)\n",
        "print(\"\ud83d\ude80 Starting Layer 12 training...\")\n",
        "print(\"   This will take ~8 hours on T4 GPU\")\n",
        "print(\"   Comprehensive training run\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "!python src/scripts/train_gemma_layer12_with_warmup_decay_samples.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcbe Save Results to Google Drive\n",
        "\n",
        "Run this after training completes to save your checkpoints to Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive and save results\n",
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "print(\"\ud83d\udcbe Saving results to Google Drive...\")\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "src_checkpoints = 'checkpoints/transcoder/gemma-2-2b/'\n",
        "dst_checkpoints = '/content/drive/MyDrive/matryoshka_checkpoints/'\n",
        "\n",
        "# Check if checkpoints exist\n",
        "if os.path.exists(src_checkpoints):\n",
        "    # Create destination directory\n",
        "    os.makedirs(dst_checkpoints, exist_ok=True)\n",
        "    \n",
        "    # Copy checkpoints\n",
        "    shutil.copytree(src_checkpoints, dst_checkpoints, dirs_exist_ok=True)\n",
        "    \n",
        "    print(f\"\u2705 Checkpoints saved to: {dst_checkpoints}\")\n",
        "    \n",
        "    # List saved files\n",
        "    print(\"\\n\ud83d\udcc1 Saved files:\")\n",
        "    for root, dirs, files in os.walk(dst_checkpoints):\n",
        "        for file in files:\n",
        "            if file.endswith(('.pt', '.json')):\n",
        "                rel_path = os.path.relpath(os.path.join(root, file), dst_checkpoints)\n",
        "                print(f\"   - {rel_path}\")\n",
        "    \n",
        "    # Also save activation samples if they exist\n",
        "    activation_samples_dirs = [d for d in os.listdir(src_checkpoints) if 'activation_samples' in d]\n",
        "    if activation_samples_dirs:\n",
        "        dst_samples = '/content/drive/MyDrive/matryoshka_samples/'\n",
        "        os.makedirs(dst_samples, exist_ok=True)\n",
        "        \n",
        "        for sample_dir in activation_samples_dirs:\n",
        "            src_sample = os.path.join(src_checkpoints, sample_dir)\n",
        "            dst_sample = os.path.join(dst_samples, sample_dir)\n",
        "            shutil.copytree(src_sample, dst_sample, dirs_exist_ok=True)\n",
        "        \n",
        "        print(f\"\u2705 Activation samples saved to: {dst_samples}\")\n",
        "    \n",
        "    print(\"\\n\ud83c\udf89 All results saved to Google Drive!\")\n",
        "    \n",
        "else:\n",
        "    print(\"\u26a0\ufe0f  No checkpoints found. Make sure training completed successfully.\")\n",
        "    print(f\"   Expected location: {src_checkpoints}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd11 How to Get a GitHub Personal Access Token\n",
        "\n",
        "### Step 1: Create a Personal Access Token\n",
        "1. Go to [GitHub Settings \u2192 Developer settings \u2192 Personal access tokens](https://github.com/settings/tokens)\n",
        "2. Click **\"Generate new token\"** \u2192 **\"Generate new token (classic)\"**\n",
        "3. Give it a name like \"Colab Training\"\n",
        "4. Set expiration (recommend 90 days)\n",
        "5. Select scopes:\n",
        "   - \u2705 **repo** (Full control of private repositories)\n",
        "   - \u2705 **read:org** (Read org and team membership)\n",
        "6. Click **\"Generate token\"**\n",
        "7. **Copy the token immediately** (you won't see it again!)\n",
        "\n",
        "### Step 2: Use the Token\n",
        "- When prompted in the notebook, paste your token\n",
        "- The token will be hidden as you type (for security)\n",
        "- The token is only used for cloning, not stored\n",
        "\n",
        "### Security Notes:\n",
        "- \ud83d\udd12 Token is only used for repository access\n",
        "- \ud83d\udd12 Token is not stored or logged anywhere\n",
        "- \ud83d\udd12 You can revoke the token anytime from GitHub settings\n",
        "- \ud83d\udd12 Token expires automatically based on your setting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udf89 Next Steps\n",
        "\n",
        "### What You've Accomplished:\n",
        "\u2705 Trained a Matryoshka Transcoder with **nested groups**  \n",
        "\u2705 Implemented hierarchical feature learning  \n",
        "\u2705 Collected activation samples for interpretability  \n",
        "\u2705 Saved results to Google Drive  \n",
        "\u2705 Evaluated model performance  \n",
        "\n",
        "### Your Files:\n",
        "- **Checkpoints**: `/content/drive/MyDrive/matryoshka_checkpoints/`\n",
        "- **Activation Samples**: `/content/drive/MyDrive/matryoshka_samples/`\n",
        "- **Evaluation Results**: In your model's `interpretability_eval/` folder\n",
        "\n",
        "### Further Analysis:\n",
        "1. **Compare with Google's Transcoder**: Use `src/eval/compare_interpretability.py`\n",
        "2. **Feature Visualization**: Analyze the activation samples in detail\n",
        "3. **Hierarchical Analysis**: Study how different groups learn different abstractions\n",
        "4. **Transfer Learning**: Use your transcoder for downstream tasks\n",
        "\n",
        "### Documentation:\n",
        "- **Quick Reference**: `QUICK_START_COLAB.md`\n",
        "- **Detailed Guide**: `COLAB_TRAINING.md`\n",
        "- **Architecture**: `NESTED_GROUPS_SUMMARY.md`\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83c\udf93 Understanding Nested Groups\n",
        "\n",
        "Your transcoder now uses **nested groups** (matching the original Matryoshka paper):\n",
        "\n",
        "| Group | Features | Description |\n",
        "|-------|----------|-------------|\n",
        "| 0 | 0-1151 | Base coarse features |\n",
        "| 1 | 0-3455 | Includes Group 0 + new features |\n",
        "| 2 | 0-8063 | Includes Groups 0,1 + new features |\n",
        "| 3 | 0-18431 | All features (complete model) |\n",
        "\n",
        "**Benefits:**\n",
        "- \ud83c\udfaf **Hierarchical Learning**: Features organize coarse \u2192 fine\n",
        "- \ud83d\udd04 **Adaptive Complexity**: Each group is a complete model\n",
        "- \ud83d\udcda **Paper Alignment**: Matches original Matryoshka design\n",
        "- \ud83e\udde0 **Better Interpretability**: Clear feature hierarchy\n",
        "\n",
        "**Happy training! \ud83d\ude80**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}